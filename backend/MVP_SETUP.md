# YSI RAG-Powered MVP Setup Guide

## Quick Start Guide

Este MVP implementa un sistema RAG (Retrieval-Augmented Generation) profesional para el platform YSI Catalyst con embeddings vectoriales y bÃºsqueda hÃ­brida.

## CaracterÃ­sticas del MVP

- âœ… **Vector Database**: PostgreSQL + pgvector para embeddings profesionales
- âœ… **Hybrid Search**: CombinaciÃ³n de bÃºsqueda vectorial + texto completo
- âœ… **Natural Language Queries**: Procesamiento inteligente de consultas
- âœ… **Data Ingestion Pipeline**: Carga automÃ¡tica de transcripciones existentes  
- âœ… **Professional Logging**: Monitoreo completo de operaciones y costos
- âœ… **RESTful API**: Endpoints completos para consultas y gestiÃ³n

## Arquitectura TÃ©cnica

```
Frontend â†’ FastAPI â†’ Search Service â†’ Embedding Service â†’ PostgreSQL + pgvector
                                  â†—
                  Hybrid Search (Vector + Full-text + RRF)
```

## InstalaciÃ³n RÃ¡pida

### 1. Prerrequisitos

```bash
# PostgreSQL con pgvector
brew install postgresql pgvector  # macOS
sudo apt install postgresql postgresql-contrib  # Ubuntu

# Python 3.8+
python --version
```

### 2. ConfiguraciÃ³n del Proyecto

```bash
cd /Users/carlos/Documents/YSI/ysi-backend

# Instalar dependencias (incluye pgvector, OpenAI, etc.)
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tu OPENAI_API_KEY y DATABASE_URL
```

### 3. Setup de Base de Datos

```bash
# ConfiguraciÃ³n automÃ¡tica completa
python setup_database.py

# Verificar que pgvector estÃ¡ funcionando
psql -d ysi_db -c "SELECT '[1,2,3]'::vector;"
```

### 4. Cargar Datos Existentes

```bash
# Crear directorio de datos
mkdir -p /Users/carlos/Documents/YSI/data/transcripts

# Copiar tus archivos de transcripciones (.txt, .json, .csv)
# Luego ejecutar:
python -m app.scripts.data_ingestion --transcripts-dir /Users/carlos/Documents/YSI/data/transcripts
```

### 5. Iniciar el Servidor

```bash
uvicorn app.main:app --reload --port 8000
```

## API Endpoints del MVP

### ğŸ” BÃºsqueda Inteligente
```bash
# Consulta de lenguaje natural
POST /api/knowledge/query
{
  "query": "Â¿QuÃ© ha dicho MarÃ­a sobre funding?",
  "search_mode": "hybrid",
  "limit": 10
}

# Encontrar contenido similar
GET /api/knowledge/search/similar?text=discussion about funding&limit=5

# EstadÃ­sticas del conocimiento
GET /api/knowledge/stats
```

### ğŸ“Š GestiÃ³n de Datos
```bash
# Procesar texto individual
POST /api/knowledge/embeddings/process?text=New meeting transcript...

# Ingestion de datos (admin only)
POST /api/knowledge/ingest
{
  "transcripts_dir": "/path/to/transcripts",
  "source_type": "meeting_transcript"
}

# Consultas recientes del usuario
GET /api/knowledge/queries/recent?limit=20
```

## Ejemplos de Uso

### 1. BÃºsqueda Contextual de Stakeholders
```python
import httpx

response = httpx.post("http://localhost:8000/api/knowledge/query", json={
    "query": "What did stakeholders say about funding challenges last month?",
    "search_mode": "hybrid",
    "context": {"time_filter": "last_30_days"},
    "limit": 5
})

results = response.json()
for result in results['results']:
    print(f"Similarity: {result['similarity']:.2f}")
    print(f"Source: {result['source_type']} - {result['metadata'].get('date')}")
    print(f"Text: {result['highlighted_snippet']}")
    print("---")
```

### 2. AnÃ¡lisis de Temas Recurrentes
```python
# Buscar patrones en reuniones
response = httpx.post("http://localhost:8000/api/knowledge/query", json={
    "query": "recurring themes in team meetings about sustainability",
    "search_mode": "semantic",
    "source_types": ["meeting_transcript"]
})
```

### 3. Seguimiento de Action Items
```python
response = httpx.post("http://localhost:8000/api/knowledge/query", json={
    "query": "action items assigned to development team this week",
    "search_mode": "hybrid",
    "context": {"query_type": "action"}
})
```

## Estructura de Archivos Creados

```
ysi-backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ text_embedding.py          # Modelo vectorial profesional
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ embedding_service.py       # Procesamiento de embeddings
â”‚   â”‚   â””â”€â”€ search_service.py          # BÃºsqueda hÃ­brida avanzada  
â”‚   â”œâ”€â”€ api/v1/
â”‚   â”‚   â””â”€â”€ knowledge.py               # API endpoints RAG
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ data_ingestion.py          # Pipeline de carga de datos
â”œâ”€â”€ alembic/versions/
â”‚   â””â”€â”€ 001_add_pgvector_and_text_embeddings.py  # MigraciÃ³n
â”œâ”€â”€ requirements.txt                    # Dependencias actualizadas
â”œâ”€â”€ setup_database.py                  # Setup automÃ¡tico
â””â”€â”€ MVP_SETUP.md                      # Esta guÃ­a
```

## CaracterÃ­sticas Avanzadas Implementadas

### ğŸ§  BÃºsqueda Inteligente
- **Hybrid Search**: Vector similarity + Full-text search + RRF fusion
- **Query Analysis**: DetecciÃ³n automÃ¡tica de intenciÃ³n y entidades
- **Contextual Ranking**: Re-ranking basado en contexto del usuario
- **Natural Language**: Soporte para consultas en espaÃ±ol e inglÃ©s

### ğŸ¯ Optimizaciones de Rendimiento  
- **HNSW Index**: Ãndice vectorial optimizado (m=16, ef_construction=64)
- **Batch Processing**: Procesamiento eficiente de documentos mÃºltiples
- **Caching**: DeduplicaciÃ³n por hash SHA256
- **Cost Tracking**: Monitoreo de tokens y costos OpenAI

### ğŸ“ˆ Monitoreo y Analytics
- **Structured Logging**: Logs estructurados JSON para todas las operaciones
- **Performance Metrics**: Tiempo de respuesta y throughput
- **Query Analytics**: Tracking de consultas populares y patrones
- **Cost Monitoring**: EstimaciÃ³n de costos AWS y OpenAI

## PrÃ³ximos Pasos

1. **Test del Sistema**: Ejecutar consultas de prueba
2. **Carga de Datos**: Importar transcripciones histÃ³ricas
3. **Ajuste Fino**: Optimizar parÃ¡metros de bÃºsqueda
4. **Frontend Integration**: Conectar con React frontend
5. **Production Setup**: Docker, monitoring, backups

## Troubleshooting

### Error: pgvector extension not found
```bash
# Instalar pgvector
brew install pgvector  # macOS
# O compilar desde source si es necesario
```

### Error: OpenAI API key not found
```bash
export OPENAI_API_KEY="your-key-here"
# O agregar a .env file
```

### Error: No embeddings found
```bash
# Verificar datos cargados
python -c "from app.services.embedding_service import embedding_service; print(embedding_service.get_embedding_stats())"
```

## DocumentaciÃ³n TÃ©cnica

- **Vector Storage**: Embeddings de 1536 dimensiones (OpenAI ada-002)
- **Chunk Strategy**: 1000 tokens con 100 tokens de overlap
- **Search Fusion**: RRF con pesos 70% vector / 30% texto
- **Index Strategy**: HNSW para vectores, GIN para metadatos, B-tree para filtros

**Â¡Tu MVP RAG estÃ¡ listo para usar! ğŸš€**