# RAGFlow Search Troubleshooting Guide

## üîç **Problema: B√∫squedas No Devuelven Resultados**

### **S√≠ntomas**
- Documentos subidos y procesados correctamente
- Estado de documentos: `success`
- Chunks creados (5 chunks total en KB)
- Tokens contados (546 tokens total)
- B√∫squedas siempre devuelven: "Sorry! No relevant content was found in the knowledge base!"

### **Configuraci√≥n Actual**
```json
{
  "embedding_model": "text-embedding-004@Gemini",
  "similarity_threshold": 0.2,
  "vector_similarity_weight": 0.3,
  "chunk_token_num": 512,
  "delimiter": "\\n",
  "layout_recognize": "DeepDOC"
}
```

### **Diagn√≥sticos Realizados**

1. **Verificaci√≥n de Documentos** ‚úÖ
   - Documentos tienen estado `DONE` en RAGFlow
   - Chunks creados correctamente
   - Tokens contados

2. **Pruebas de B√∫squeda**
   - B√∫squeda via YSI Backend API ‚ùå
   - B√∫squeda directa en RAGFlow API ‚ùå
   - Diferentes queries probadas:
     - "What is YSI?" ‚ùå
     - "Youth Startup Initiative" ‚ùå
     - "mentorship programs" ‚ùå
     - "YSI services mentorship funding" ‚ùå

3. **Verificaci√≥n de Servicios**
   - Elasticsearch: Running (healthy)
   - RAGFlow Server: Running
   - No errores en logs

### **Posibles Causas**

1. **Modelo de Embeddings No Configurado**
   - Gemini API key no configurada
   - Modelo no disponible/activo
   - Error silencioso en generaci√≥n de embeddings

2. **Problema de Indexaci√≥n**
   - Documentos procesados pero no indexados
   - √çndice de Elasticsearch corrupto o vac√≠o
   - Mismatch entre embedding model para indexar vs buscar

3. **Configuraci√≥n de B√∫squeda**
   - `similarity_threshold` muy restrictivo (aunque 0.2 es bajo)
   - `vector_similarity_weight` inadecuado

### **Soluciones Propuestas**

#### 1. **Verificar API Key de Gemini**
```bash
# En el contenedor RAGFlow
docker-compose exec ragflow env | grep -i gemini
docker-compose exec ragflow env | grep -i api_key
```

#### 2. **Cambiar Modelo de Embeddings**
Considerar usar un modelo local o diferente:
- BAAI/bge-large-zh-v1.5
- OpenAI text-embedding-ada-002
- Modelo local de Ollama

#### 3. **Re-indexar Documentos**
```bash
# Eliminar y volver a procesar documentos
# O crear un nuevo KB con modelo diferente
```

#### 4. **Verificar Elasticsearch**
```bash
# Verificar √≠ndices
curl -X GET "localhost:9200/_cat/indices?v"

# Buscar documentos en el √≠ndice
curl -X GET "localhost:9200/ragflow*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match_all": {}
  },
  "size": 1
}'
```

#### 5. **Usar Modelo de Embeddings Local**
En lugar de Gemini, configurar un modelo que no requiera API externa:
1. Modificar configuraci√≥n del KB
2. Usar modelo de Sentence Transformers
3. Re-procesar documentos

### **Configuraci√≥n Alternativa Recomendada**

```json
{
  "embedding_model": "BAAI/bge-large-zh-v1.5",
  "similarity_threshold": 0.1,
  "vector_similarity_weight": 0.7,
  "chunk_token_num": 256,
  "delimiter": "\\n\\n"
}
```

### **Pasos para Resoluci√≥n**

1. **Verificar configuraci√≥n de Gemini**
   ```bash
   # Buscar en archivos de configuraci√≥n
   grep -r "GEMINI" /ragflow/
   grep -r "API_KEY" /ragflow/
   ```

2. **Crear nuevo KB con modelo diferente**
   - Usar interfaz web de RAGFlow
   - Seleccionar modelo de embeddings local
   - Re-subir documentos

3. **Monitorear logs durante procesamiento**
   ```bash
   docker-compose logs -f ragflow | grep -E "(embedding|vector|index)"
   ```

### **Workaround Temporal**

Mientras se resuelve el problema de embeddings:
1. Usar RAGFlow solo para almacenamiento de documentos
2. Implementar b√∫squeda basada en keywords en el backend
3. Usar full-text search de PostgreSQL como fallback

### **Referencias**
- [RAGFlow Embedding Models](https://docs.ragflow.io/docs/dev/configurations#embedding-models)
- [Elasticsearch Vector Search](https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search.html)
- [Gemini API Setup](https://ai.google.dev/tutorials/setup)

---

**√öltima actualizaci√≥n**: 2025-09-25 22:35
**Estado**: üî¥ Pendiente de resoluci√≥n
